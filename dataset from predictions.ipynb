{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from os import walk, getcwd\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baboons',\n",
       " 'black and white colobus',\n",
       " 'cattle',\n",
       " 'chimpanzee',\n",
       " 'giant forest hog',\n",
       " 'leopard',\n",
       " 'red colobus',\n",
       " 'red river hog',\n",
       " 'red_duiker',\n",
       " 'small antelope',\n",
       " 'small grey duiker',\n",
       " 'sooty mangabey',\n",
       " 'squirrel',\n",
       " 'warthog',\n",
       " 'yellow backed duiker',\n",
       " 'zebra duiker']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set folder\n",
    "root_directory = '/media/sergio/0C5EC1615EC14464/msc_data/bounding_boxes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['baboons',\n",
       " 'black and white colobus',\n",
       " 'cattle',\n",
       " 'chimpanzee',\n",
       " 'giant forest hog',\n",
       " 'leopard',\n",
       " 'red colobus',\n",
       " 'red river hog',\n",
       " 'red_duiker',\n",
       " 'small antelope',\n",
       " 'small grey duiker',\n",
       " 'sooty mangabey',\n",
       " 'squirrel',\n",
       " 'warthog',\n",
       " 'yellow backed duiker',\n",
       " 'zebra duiker']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get species names\n",
    "species_list = os.listdir(root_directory)\n",
    "species_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all files, with filename as subject_id, and folder name as species\n",
    "for species in species_list:\n",
    "    files = [s for s in os.listdir(f\"{root_directory}/{species}\") if \".txt\" in s]\n",
    "    with open(f\"{species}.csv\", 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for file in files:\n",
    "            data = pd.read_csv(f\"{root_directory}/{species}/{file}\", sep= \" \", header=None)\n",
    "            for index, row in data.iterrows():\n",
    "                    writer.writerow([file.split(\".\")[0], species, row[0], row[1], row[2], row[3], row[5], row[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red_duiker.csv',\n",
       " 'chimpanzee.csv',\n",
       " 'red colobus.csv',\n",
       " 'black and white colobus.csv',\n",
       " 'zebra duiker.csv',\n",
       " 'baboons.csv',\n",
       " 'leopard.csv',\n",
       " 'small grey duiker.csv',\n",
       " 'sooty mangabey.csv',\n",
       " 'squirrel.csv',\n",
       " 'cattle.csv',\n",
       " 'red river hog.csv',\n",
       " 'small antelope.csv',\n",
       " 'yellow backed duiker.csv',\n",
       " 'giant forest hog.csv']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir(f\"bounding_boxes/\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-e0456ae08685>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"bounding_boxes/{file}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mno_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtraining_image_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mno_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mvalidation_image_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.7\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mno_rows\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mno_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_size\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtest_image_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mno_rows\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mno_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "# create the training files\n",
    "training_size = 1990\n",
    "validation_size = 560\n",
    "test_size = 280\n",
    "date = \"2020-02-14\"\n",
    "# open csv\n",
    "files = os.listdir(f\"bounding_boxes/\")\n",
    "# iterate over species files\n",
    "for file in files:\n",
    "    data = pd.read_csv(f\"bounding_boxes/{file}\", sep= \",\", header=None)\n",
    "    no_rows = data.shape[0]\n",
    "    training_image_rows = np.random.choice(int(0.7 * no_rows), 2000,  replace=False)\n",
    "    validation_image_rows = [x+ int(0.7 * no_rows) for x in np.random.choice(int(0.2 * no_rows), validation_size,  replace=False)]\n",
    "    test_image_rows = [x+ int(0.9 * no_rows) for x in np.random.choice(int(0.1 * no_rows), test_size,  replace=False)]\n",
    "\n",
    "    # sample from split and add to csv\n",
    "    training_images = data.iloc[training_image_rows,:]\n",
    "    validation_images = data.iloc[validation_image_rows,:]\n",
    "    test_images = data.iloc[test_image_rows,:]\n",
    "\n",
    "    # write to csv\n",
    "    with open(f\"training_{date}.csv\", 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for index, row in training_images.iterrows():\n",
    "                writer.writerow(row)\n",
    "                \n",
    "    with open(f\"validation_{date}.csv\", 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for index, row in validation_images.iterrows():\n",
    "                writer.writerow(row)\n",
    "\n",
    "    with open(f\"test_{date}.csv\", 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        for index, row in test_images.iterrows():\n",
    "                writer.writerow(row)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to txt file and add training and test images to folder\n",
    "\n",
    "image_id = 1\n",
    "\n",
    "# start a txt file\n",
    "with open(f\"training_{date}.csv\", 'a') as f:\n",
    "    writer = csv.writer(f)   \n",
    "    \n",
    "    # iterate over csv file\n",
    "    for index, row in test_images.iterrows():\n",
    "        subject_id = row[0]\n",
    "        frame = row[5]    \n",
    "        # open clip and select frame\n",
    "        video = cv2.VideoCapture(f\"{videos_path}/{clip}.mp4\")\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, frame)\n",
    "        _, image = video.read()\n",
    "        filepath = f\"{save_directory}/{image_id}.png\"\n",
    "        # save frame in correct directory\n",
    "        cv2.imwrite(filepath, image)\n",
    "\n",
    "        # write line in text filepath,x1,y1,x2,y2,class_name\n",
    "        writer.writerow([filepath,row[1], row[2], row[3], row[4], row[5]])\n",
    "        \n",
    "        image_id += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
